================================================================================
        NTRIA MVP - GRAPH RAG DEVELOPMENT TODO LIST
================================================================================
Project: Nigeria Tax Reform Intelligence Assistant (NTRIA)
Architecture: Graph RAG + Neo4j + FastAPI + Next.js
Goal: Launch intelligent web bot with Graph RAG for Tax Reform Challenge 2025
Timeline: 5-6 Weeks to MVP
================================================================================

================================================================================
PHASE 1: WEEKS 1-2 - SETUP & GRAPH DESIGN
================================================================================

[ ] WEEK 1: PROJECT INITIALIZATION & ARCHITECTURE
================================================================================

    [ ] 1.1 Repository & Project Setup
        [ ] Initialize GitHub repository structure
        [ ] Create folder structure:
            - /frontend (React/Next.js)
            - /backend (FastAPI)
            - /data (tax documents)
            - /scripts (document processing & extraction)
            - /graph (Neo4j queries, schemas)
            - /docs (documentation)
        [ ] Create .gitignore file
        [ ] Create .env.example file with all required vars

    [ ] 1.2 Frontend Setup
        [ ] Initialize Next.js project (npx create-next-app@latest)
        [ ] Install core dependencies:
            - axios (API calls)
            - tailwindcss (styling)
            - react-markdown (render formatted responses)
            - zustand or context-api (state management)
        [ ] Set up basic project structure:
            - /pages/index.js (main chat page)
            - /components/ChatWindow.jsx
            - /components/MessageBubble.jsx
            - /components/InputField.jsx
            - /styles/globals.css
        [ ] Configure Tailwind CSS
        [ ] Set up responsive mobile/desktop layout

    [ ] 1.3 Backend Setup
        [ ] Initialize FastAPI project
        [ ] Create requirements.txt with dependencies:
            - fastapi
            - uvicorn
            - python-dotenv
            - openai
            - langchain
            - neo4j (for Neo4j connection)
            - py2neo (alternative Neo4j library)
            - pydantic (data validation)
            - pdfplumber (PDF extraction)
            - python-dotenv
            - aiohttp (async HTTP)
        [ ] Create basic FastAPI app structure:
            - /app/main.py (FastAPI app initialization)
            - /app/routes (API endpoints)
            - /app/services (business logic)
            - /app/models (pydantic models)
            - /app/config (configuration)
        [ ] Set up CORS for frontend communication
        [ ] Create health check endpoint (/health)

    [ ] 1.4 Get Accounts & API Keys
        [ ] OpenAI API account â†’ Get API key
        [ ] Neo4j Cloud account â†’ Create instance â†’ Get connection credentials
        [ ] Pinecone account (optional, for vector DB) â†’ API key
        [ ] Set all keys in .env file securely
        [ ] Test API connectivity for each service


[ ] WEEK 2: DOCUMENT PROCESSING & GRAPH SCHEMA
================================================================================

    [ ] 2.1 Document Collection & Preprocessing
        [ ] Download/collect tax documents:
            - 2025 Tax Reform Act PDF (main document)
            - FIRS FAQs and guidelines
            - Government circulars on VAT, PAYE, DST
            - Tax filing procedures
        [ ] Store all PDFs in /data folder
        [ ] Create document inventory:
            - Document name
            - Source
            - Total pages
            - Key topics

    [ ] 2.2 Build Document Extraction Pipeline
        [ ] Create script: extract_text_from_pdf.py
            - Use pdfplumber to extract text from all PDFs
            - Handle multi-page documents
            - Preserve formatting (section headers, lists)
            - Output: clean text files
        [ ] Create script: preprocess_text.py
            - Normalize text (remove extra whitespace, standardize formatting)
            - Section tokenization (group by tax type, process, etc.)
            - Add metadata (document name, page number, section)
            - Output: cleaned JSON with metadata
        [ ] Create script: chunk_documents.py
            - Split into 500-token chunks with 50-token overlap
            - Preserve context across chunks
            - Add chunk metadata (doc name, page, chunk index)
            - Output: chunks in JSON format

    [ ] 2.3 Design Neo4j Knowledge Graph Schema
        [ ] Define Node Types:
            - Tax (type, rate, effective_date, description)
            - Taxpayer (category, resident, income_threshold)
            - Agency (name, jurisdiction, contact)
            - Process (name, duration, documentation, frequency)
            - Threshold (amount, currency, logic)
            - Penalty (type, amount, percentage, basis)
            - Deadline (event, date, frequency, reminder_days)
            - Rule (content, policy_ref, effective_date, status)
            - Document (title, source, pages, version)
            - Exception (description, applies_to, conditions)
        [ ] Define Relationship Types:
            - applies_to, enforced_by, requires, defined_in
            - liable_for, triggers, has_exception, overrides
            - depends_on, exempts, penalizes, has_deadline
        [ ] Create Cypher schema definition file
        [ ] Document all node & relationship properties

    [ ] 2.4 Set Up Neo4j Database
        [ ] Create Neo4j Cloud instance
        [ ] Connect to instance from backend
        [ ] Create indices for fast queries:
            - Index on Tax.type
            - Index on Taxpayer.category
            - Index on Deadline.date
        [ ] Test basic Cypher queries manually
        [ ] Create backup/snapshot


================================================================================
PHASE 2: WEEKS 3-4 - GRAPH POPULATION & ENTITY EXTRACTION
================================================================================

[ ] WEEK 3: ENTITY EXTRACTION & GRAPH POPULATION
================================================================================

    [ ] 3.1 Build Entity Extraction Pipeline
        [ ] Create script: extract_entities.py
            - For each document chunk, call GPT-4 with extraction prompt:
              """
              Extract all entities and relationships:
              - Tax types (VAT, PAYE, DST, CGT, etc.)
              - Taxpayer categories
              - Tax agencies
              - Processes and procedures
              - Thresholds and amounts
              - Deadlines and dates
              - Penalties
              - Rules and exceptions
              
              Return as structured JSON
              """
            - Parse GPT response
            - Validate extracted entities
            - Add source references
        [ ] Create quality checks:
            - Verify extracted entities exist in schema
            - Check for duplicates
            - Validate amounts and dates format
        [ ] Test extraction on sample document chunks
        [ ] Refine extraction prompt based on results

    [ ] 3.2 Build Relationship Extraction
        [ ] Create script: extract_relationships.py
            - For each chunk, identify relationships:
              - Which taxes apply to which taxpayers?
              - What processes are required for each tax?
              - Which deadlines apply to which processes?
              - What penalties for which violations?
            - Extract as: (entity1, relationship_type, entity2)
            - Add confidence scores
        [ ] Create relationship validation:
            - Check if both entities exist
            - Validate relationship type is defined
            - Check for logical consistency

    [ ] 3.3 Populate Neo4j Graph
        [ ] Create script: populate_graph.py
            - For each extracted entity:
              - Check if node exists
              - If not, create node with properties
              - If exists, update properties if needed
            - For each extracted relationship:
              - Create relationship edge
              - Add relationship properties (confidence, source, date)
        [ ] Batch operations for efficiency (transaction handling)
        [ ] Log all operations for audit trail
        [ ] Handle duplicates intelligently (merge similar entities)

    [ ] 3.4 Validate Graph Integrity
        [ ] Run graph validation queries:
            - Count nodes by type
            - Count relationships by type
            - Check for orphaned nodes
            - Verify all expected relationships exist
        [ ] Create test queries on populated graph:
            - "Get all taxes applicable to freelancers"
            - "Get deadlines for PAYE tax"
            - "Find exemptions for education sector"
        [ ] Document any missing or incorrect data
        [ ] Create manual review checklist for verification


[ ] WEEK 4: VECTOR DATABASE & HYBRID RETRIEVAL
================================================================================

    [ ] 4.1 Set Up Vector Database
        [ ] Choose: Pinecone (cloud) or Chroma (local)
        [ ] If Pinecone:
            - Create account and index
            - Configure index dimension (1536 for OpenAI)
            - Set up API key and test connection
        [ ] If Chroma:
            - Install locally or containerize
            - Configure persistence
        [ ] Create database initialization script

    [ ] 4.2 Generate & Store Embeddings
        [ ] Create script: generate_embeddings.py
            - For each document chunk:
              - Convert to embedding using OpenAI API
              - Store: (chunk_id, embedding_vector, chunk_text, metadata)
            - Handle API rate limiting
            - Batch requests for efficiency
        [ ] Store embeddings in vector DB with metadata:
            - chunk_id, document_source, page_number, chunk_text
        [ ] Verify embedding quality (test retrieval)

    [ ] 4.3 Build Hybrid Retrieval Module
        [ ] Create /backend/services/retriever.py
            - Function: retrieve_from_graph(query, depth=2)
              - Extract entities from query (using GPT-4)
              - Generate Cypher query
              - Execute on Neo4j
              - Return ranked results
            - Function: retrieve_from_vectors(query, top_k=5)
              - Convert query to embedding
              - Semantic search in vector DB
              - Return top-K similar chunks
            - Function: hybrid_retrieve(query)
              - Call both retriever functions
              - Fuse results (rank by relevance)
              - De-duplicate
              - Return enriched context
        [ ] Add confidence scoring
        [ ] Add source attribution

    [ ] 4.4 Test Retrieval Pipeline
        [ ] Test 10 sample queries:
            - "What are VAT obligations?"
            - "Freelancer tax requirements?"
            - "PAYE filing deadline?"
            - etc.
        [ ] Verify both graph and vector retrieval working
        [ ] Check response quality and relevance
        [ ] Document any issues


================================================================================
PHASE 3: WEEKS 5-6 - LLM INTEGRATION & WEB INTERFACE
================================================================================

[ ] WEEK 5: LLM INTEGRATION & BACKEND API
================================================================================

    [ ] 5.1 Build Response Generation Module
        [ ] Create /backend/services/generator.py
            - Function: generate_response(query, context)
              - Build prompt with context
              - Call GPT-4 API
              - Stream response to user
              - Add source citations
              - Validate no hallucinations
        [ ] Create prompt templates:
            - System prompt (define NTRIA persona)
            - Context template (structured knowledge)
            - Few-shot examples
        [ ] Implement response validation:
            - Check response against source documents
            - Verify facts are in context
            - Confidence scoring

    [ ] 5.2 Build Graph RAG Pipeline
        [ ] Create /backend/services/graph_rag.py
            - Orchestrate full pipeline:
              1. Parse user query
              2. Retrieve from graph & vectors
              3. Assemble context
              4. Generate response with LLM
              5. Validate and cite sources
            - Handle error cases
            - Add logging

    [ ] 5.3 Create API Endpoints
        [ ] POST /api/v1/chat
            - Request: {message, session_id, context}
            - Response: {response, sources, confidence, graph_path}
            - Error handling for invalid requests
        [ ] GET /api/v1/health
            - Simple health check
        [ ] GET /api/v1/entities
            - Return available entity types (for UI autocomplete)
        [ ] POST /api/v1/graph/search
            - Custom graph search endpoint
        [ ] Add rate limiting and authentication
        [ ] Document all endpoints

    [ ] 5.4 Test Backend Endpoints
        [ ] Use Postman or curl to test all endpoints
        [ ] Test with sample queries
        [ ] Verify responses are correct
        [ ] Check error handling
        [ ] Performance testing (response times)


[ ] WEEK 6: FRONTEND DEVELOPMENT & DEPLOYMENT
================================================================================

    [ ] 6.1 Build Chat Interface
        [ ] Create components:
            - ChatWindow.jsx (main container)
            - MessageBubble.jsx (message display)
            - InputField.jsx (user input + send button)
            - SidePanel.jsx (FAQ, quick links)
            - SourceCitation.jsx (display sources)
        [ ] Implement features:
            - Display bot and user messages
            - Auto-scroll to latest message
            - Typing indicator while loading
            - Error message display
            - Source attribution on responses

    [ ] 6.2 Connect Frontend to Backend
        [ ] Create /frontend/services/api.js
            - setUpAxiosInstance()
            - sendMessage(message)
            - getEntities()
        [ ] Implement state management:
            - Store conversation history
            - Store current session
            - Manage loading states
        [ ] Handle API errors gracefully
        [ ] Add retry logic for failed requests

    [ ] 6.3 UI/UX Polish
        [ ] Responsive design (mobile/tablet/desktop)
        [ ] Add loading spinner during API call
        [ ] Add welcome message on load
        [ ] Display sample questions users can click
        [ ] Color scheme: green/blue theme (tax-related)
        [ ] Dark/light mode toggle (optional)
        [ ] Accessibility (WCAG 2.1 AA)

    [ ] 6.4 Test Frontend
        [ ] Manual testing on multiple devices
        [ ] Test edge cases:
            - Very long responses
            - Multiple messages in quick succession
            - Network disconnection
            - API errors
        [ ] Performance testing (load time, responsiveness)

    [ ] 6.5 Deploy Application
        [ ] Deploy Frontend:
            - Push to GitHub
            - Deploy to Vercel (automatic from main)
            - Test deployed version
        [ ] Deploy Backend:
            - Push to GitHub
            - Deploy to Render/Railway
            - Set environment variables
            - Test deployed API
        [ ] Run end-to-end test on deployed app
        [ ] Configure custom domain (optional)


================================================================================
TESTING & DEMO PREPARATION
================================================================================

[ ] 6.6 Comprehensive Testing
================================================================================

    [ ] Create 10+ sample test queries:
        [ ] "What are the tax brackets under 2025 reform?"
        [ ] "How does NYSC affect my tax obligations?"
        [ ] "What are deductions available for students?"
        [ ] "When is the VAT filing deadline?"
        [ ] "What are penalties for late tax payment?"
        [ ] "Am I liable for VAT as a freelancer earning â‚¦2M?"
        [ ] "Explain the new Digital Service Tax"
        [ ] "What documents do I need for PAYE registration?"

    [ ] Test all queries on deployed MVP
        [ ] Verify accuracy of responses (>85% target)
        [ ] Check response time (<2 seconds target)
        [ ] Verify source citations are correct
        [ ] Test on mobile and desktop
        [ ] Test on different browsers

    [ ] Verify Graph RAG pipeline:
        [ ] Graph queries return correct entities
        [ ] Vector retrieval returns relevant chunks
        [ ] Hybrid results are properly ranked
        [ ] Context is accurately assembled
        [ ] LLM responses are factual

    [ ] Performance optimization:
        [ ] Optimize database queries
        [ ] Add caching where appropriate
        [ ] Minimize frontend bundle size
        [ ] Test under load


[ ] 6.7 Demo Preparation
================================================================================

    [ ] Prepare demo script:
        [ ] 3-4 key questions to demonstrate
        [ ] Show graph visualization (optional)
        [ ] Highlight source citations
        [ ] Show response accuracy

    [ ] Create supporting materials:
        [ ] Architecture diagram
        [ ] Knowledge graph schema diagram
        [ ] Pipeline flow diagram
        [ ] Screenshot gallery

    [ ] Prepare presentation:
        [ ] 2-3 minute demo video (backup)
        [ ] Slide deck explaining Graph RAG advantage
        [ ] Show metrics and test results
        [ ] Discuss future roadmap

    [ ] Final checks:
        [ ] All endpoints working
        [ ] No errors in console
        [ ] All features functional
        [ ] Backup deployment ready


================================================================================
DOCUMENTATION & SUBMISSION
================================================================================

[ ] 6.8 Final Documentation
================================================================================

    [ ] Update README.md:
        [ ] Project description
        [ ] Features overview
        [ ] Setup instructions (local + deployed)
        [ ] API documentation
        [ ] Graph schema explanation
        [ ] Deployment instructions

    [ ] Create additional docs:
        [ ] ARCHITECTURE.md (detailed system design)
        [ ] GRAPH_SCHEMA.md (Neo4j schema reference)
        [ ] API.md (endpoint documentation)
        [ ] SETUP.md (local development setup)

    [ ] Prepare for submission:
        [ ] Ensure all code is pushed to GitHub
        [ ] Create release/tag for submission version
        [ ] Prepare all deliverables
        [ ] Final code review
        [ ] Submit to Tax Reform Challenge 2025


================================================================================
POST-MVP: PHASE 2 FEATURES (Optional for Competition)
================================================================================

[ ] Multi-language support (Hausa, Yoruba, Igbo)
[ ] Voice input feature
[ ] Analytics dashboard
[ ] Gamified quizzes
[ ] Tax calculator
[ ] Community Q&A features
[ ] Push notifications


================================================================================
QUICK REFERENCE - KEY COMMANDS
================================================================================

FRONTEND:
  cd frontend
  npm install
  npm run dev              # Development server
  npm run build            # Production build

BACKEND:
  cd backend
  python -m venv venv
  source venv/bin/activate
  pip install -r requirements.txt
  uvicorn app.main:app --reload

GRAPH OPERATIONS:
  # Test Neo4j connection
  python scripts/test_neo4j_connection.py
  
  # Extract entities
  python scripts/extract_entities.py
  
  # Populate graph
  python scripts/populate_graph.py
  
  # Test retrieval
  python scripts/test_retrieval.py

DEPLOYMENT:
  # Frontend (Vercel)
  git push origin main     # Auto-deploys
  
  # Backend (Render/Railway)
  git push origin main     # Auto-deploys


================================================================================
SUCCESS CRITERIA FOR MVP
================================================================================

Frontend:
  âœ“ Chat interface functional and responsive
  âœ“ Messages display correctly with formatting
  âœ“ Source citations visible on all responses
  âœ“ Mobile-friendly design
  âœ“ <3 second page load time

Backend:
  âœ“ All endpoints return correct responses
  âœ“ Graph queries execute successfully
  âœ“ Vector search returns relevant chunks
  âœ“ Hybrid retrieval properly fuses results
  âœ“ LLM generates accurate responses
  âœ“ <2 second API response time

Graph RAG:
  âœ“ Neo4j populated with tax entities
  âœ“ Multi-hop queries work correctly
  âœ“ Entity extraction >90% accurate
  âœ“ Relationship extraction captures tax logic

Demo:
  âœ“ 10+ test questions answered with >85% accuracy
  âœ“ Live demo runs without errors
  âœ“ Deployed app is stable and accessible
  âœ“ All deliverables ready for judges


================================================================================
IMPORTANT NOTES
================================================================================

1. Keep API keys secure - never commit to GitHub
2. Use .env file for all credentials
3. Test locally before deploying
4. Document decisions and changes in commit messages
5. Regular backups of Neo4j database
6. Monitor costs during development (API usage)
7. Start simple, iterate and improve
8. Focus on accuracy over features for MVP


================================================================================
Good Luck! ðŸš€ You've got this!
================================================================================
